{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragathi528/18K41A0528-NLP-Assignments/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9w1x3GaPxPh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "619470a9-786d-4f62-ae54-a7d3136bfa04"
      },
      "source": [
        "#convert the above paragraph into vector using\n",
        "'''1.Word2vec\n",
        "2.USE\n",
        "3.ELMO\n",
        "4.GP2\n",
        "5.Sentence-BERT'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.Word2vec\\n2.USE\\n3.ELMO\\n4.GP2\\n5.Sentence-BERT'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEfrxdsqeHqx"
      },
      "source": [
        "my_string='''A paragraph is a series of sentences that are organized and coherent, and are \n",
        "all  related  to  a  single  topic.  Almost  every  piece  of  writing  you  do  that  is \n",
        "longer  than  a  few  sentences  should  be  organized  into  paragraphs.  This  is \n",
        "because paragraphs show a reader where the subdivisions of an essay begin \n",
        "and end, and thus help the reader see the organization of the essay and grasp \n",
        "its main points.\n",
        "Paragraphs  can  contain  many  different  kinds  of  information.  A  paragraph \n",
        "could  contain  a  series  of  brief  examples  or  a  single  long  illustration  of  a \n",
        "general  point.  It  might  describe  a  place,  character,  or  process;  narrate  a \n",
        "series of events; compare or contrast two or more things; classify items into \n",
        "categories;  or  describe  causes  and  effects.  Regardless  of  the  kind  of \n",
        "information they contain, all paragraphs share certain characteristics. One \n",
        "of the most important of these is a topic sentence.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWPrqJD0Q2F6",
        "outputId": "233fac8b-9776-4cbc-86f3-02ae67a4c96c"
      },
      "source": [
        "print(my_string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A paragraph is a series of sentences that are organized and coherent, and are \n",
            "all  related  to  a  single  topic.  Almost  every  piece  of  writing  you  do  that  is \n",
            "longer  than  a  few  sentences  should  be  organized  into  paragraphs.  This  is \n",
            "because paragraphs show a reader where the subdivisions of an essay begin \n",
            "and end, and thus help the reader see the organization of the essay and grasp \n",
            "its main points.\n",
            "Paragraphs  can  contain  many  different  kinds  of  information.  A  paragraph \n",
            "could  contain  a  series  of  brief  examples  or  a  single  long  illustration  of  a \n",
            "general  point.  It  might  describe  a  place,  character,  or  process;  narrate  a \n",
            "series of events; compare or contrast two or more things; classify items into \n",
            "categories;  or  describe  causes  and  effects.  Regardless  of  the  kind  of \n",
            "information they contain, all paragraphs share certain characteristics. One \n",
            "of the most important of these is a topic sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGDM41dNU8RC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa13a839-6725-4722-bfa0-557d9075a647"
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import gensim\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import word2vec\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piwG3r_ofmdy"
      },
      "source": [
        "#1.word2vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gARkF81dfrK7",
        "outputId": "aa470679-825d-4487-9d25-0940f31ac99d"
      },
      "source": [
        "#code to convert paragraph to sentences\n",
        "def essay_to_sentences(paragraph):\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    raw_sentences = tokenizer.tokenize(paragraph.strip())\n",
        "    sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 0:\n",
        "            sentences.append((raw_sentence))\n",
        "    return sentences\n",
        "\n",
        "sentences=essay_to_sentences(my_string)\n",
        "\n",
        "sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A paragraph is a series of sentences that are organized and coherent, and are \\nall  related  to  a  single  topic.',\n",
              " 'Almost  every  piece  of  writing  you  do  that  is \\nlonger  than  a  few  sentences  should  be  organized  into  paragraphs.',\n",
              " 'This  is \\nbecause paragraphs show a reader where the subdivisions of an essay begin \\nand end, and thus help the reader see the organization of the essay and grasp \\nits main points.',\n",
              " 'Paragraphs  can  contain  many  different  kinds  of  information.',\n",
              " 'A  paragraph \\ncould  contain  a  series  of  brief  examples  or  a  single  long  illustration  of  a \\ngeneral  point.',\n",
              " 'It  might  describe  a  place,  character,  or  process;  narrate  a \\nseries of events; compare or contrast two or more things; classify items into \\ncategories;  or  describe  causes  and  effects.',\n",
              " 'Regardless  of  the  kind  of \\ninformation they contain, all paragraphs share certain characteristics.',\n",
              " 'One \\nof the most important of these is a topic sentence.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6reAVO_vfrcI",
        "outputId": "0dd5e5bc-9114-46c7-be54-c47d5e6047e6"
      },
      "source": [
        "wordvecs=[nltk.word_tokenize(sent) for sent in sentences]\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stops=list(set(stopwords.words(\"english\")))\n",
        "\n",
        "\n",
        "for i in wordvecs:\n",
        "  for j in i:\n",
        "    if j in stops:\n",
        "      i.remove(j)\n",
        "    elif len(j)==1:\n",
        "      i.remove(j)\n",
        "\n",
        "model=gensim.models.Word2Vec(wordvecs,min_count=1,size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNNxOOdkhL0C",
        "outputId": "f6901778-6fa2-4266-8bbb-950cfa4b2928"
      },
      "source": [
        "#printing vector form of word 'paragraph'\n",
        "model['paragraph']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.99511340e-03,  1.32018132e-02,  2.34303204e-03, -5.46657201e-03,\n",
              "       -7.23520061e-05,  8.97016097e-03, -5.75057464e-04, -1.18803885e-02,\n",
              "        1.53553784e-02,  1.47455167e-02,  9.96677577e-03,  9.81054734e-03,\n",
              "       -4.85708145e-03,  2.73453468e-03,  9.15499777e-03, -1.02671077e-02,\n",
              "       -9.16066673e-03, -9.67284944e-03,  9.47432034e-03, -1.41909262e-02,\n",
              "       -2.45438446e-03,  1.21236620e-02,  7.09140068e-03,  1.11299232e-02,\n",
              "       -2.24200031e-03, -3.18421912e-03, -5.80808148e-03, -2.90780189e-03,\n",
              "        1.18916081e-02,  5.58140874e-03, -9.21736564e-03, -1.47118540e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onO3x8iehQmy",
        "outputId": "6149fc8e-3423-4462-87af-6a875d5ef5df"
      },
      "source": [
        "#finding similar words of word 'sentence' in given paragraph\n",
        "model.most_similar('sentence')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('characteristics', 0.5335047245025635),\n",
              " ('points', 0.4338359832763672),\n",
              " ('might', 0.39026063680648804),\n",
              " ('related', 0.3472822308540344),\n",
              " ('every', 0.29414859414100647),\n",
              " ('see', 0.27513179183006287),\n",
              " ('character', 0.26720166206359863),\n",
              " ('longer', 0.2405598759651184),\n",
              " ('kinds', 0.22019103169441223),\n",
              " ('This', 0.2171173244714737)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWAdGCokhNb8"
      },
      "source": [
        "#2.USE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R_1S7qKh4mf",
        "outputId": "37014673-bc1b-4e7c-e52f-65db82fecb8e"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "use=hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "#converting to vectors\n",
        "embeddings=use(sentences)\n",
        "print(embeddings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.01419854 -0.01116286  0.06808718 ... -0.08247866 -0.02446434\n",
            "   0.05483037]\n",
            " [ 0.02902018 -0.00415597  0.07664446 ... -0.06830524 -0.00835191\n",
            "   0.04397805]\n",
            " [ 0.06417768 -0.01383496  0.05436629 ... -0.06510986  0.03140234\n",
            "   0.05601776]\n",
            " ...\n",
            " [ 0.03035337 -0.04422743  0.05888064 ... -0.06469322  0.03180374\n",
            "   0.06408841]\n",
            " [ 0.0167906   0.00667928  0.01125342 ... -0.01703941  0.00186954\n",
            "   0.03127917]\n",
            " [ 0.00255486 -0.05832284  0.01486255 ... -0.09906971 -0.07840379\n",
            "   0.06731212]], shape=(8, 512), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbKPLpnXiQxw",
        "outputId": "9318479c-2f11-4519-d2f3-03f339470dbe"
      },
      "source": [
        "print(\"shape= \",embeddings[0].shape)\n",
        "#each sentence is converted into vector having 512 values\n",
        "print(\"The sentence: \",sentences[0],\"\\n is converted as : \\n{}\".format(embeddings[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=  (512,)\n",
            "The sentence:  A paragraph is a series of sentences that are organized and coherent, and are \n",
            "all  related  to  a  single  topic. \n",
            " is converted as : \n",
            "[ 0.01419854 -0.01116286  0.06808718  0.07700881 -0.03895407  0.027068\n",
            "  0.00257173  0.02014753 -0.03788976  0.04260812 -0.01521275  0.00533997\n",
            " -0.07209948  0.0367611  -0.06254542 -0.09687163 -0.01923382  0.05190525\n",
            " -0.09006073 -0.05622269  0.01608456  0.06809609 -0.01020567  0.03836553\n",
            " -0.00381103  0.02741722 -0.04025005 -0.06196541 -0.01051786 -0.02963339\n",
            "  0.08044114 -0.01431125  0.01068422  0.00968601 -0.07914273  0.03594946\n",
            "  0.05300874  0.01727414  0.01145495  0.03765574 -0.01705824  0.0573004\n",
            "  0.03334488  0.05453339  0.0676109   0.00181276  0.00020469 -0.0520896\n",
            " -0.02940499  0.0181704   0.01051127  0.0668782   0.00589057 -0.02306652\n",
            " -0.015832   -0.02011859 -0.0044348   0.05842008  0.02924796  0.01362076\n",
            " -0.03265018 -0.05013916  0.05568229  0.05168435  0.04828951  0.03396421\n",
            "  0.04861676 -0.02090659  0.05732653 -0.07062454  0.03618922  0.0002725\n",
            "  0.05169725  0.05082001 -0.08100159  0.0594523  -0.06141003  0.04119882\n",
            "  0.00666001  0.00498238 -0.05175359 -0.05802553  0.04362234  0.03920698\n",
            "  0.02351651  0.0236355  -0.01320558 -0.00359884 -0.0920387  -0.04384848\n",
            "  0.0470303   0.00830702  0.02057693 -0.02224192  0.01596827  0.08983537\n",
            " -0.08993679 -0.05704732  0.06437988  0.00160985  0.02142301 -0.0355121\n",
            " -0.0748313   0.05446067 -0.01625266  0.00647785  0.04780556  0.04473713\n",
            " -0.04153081 -0.01434749 -0.00144598  0.01172802  0.0053136   0.03403137\n",
            "  0.01407714  0.01894077 -0.0845018  -0.01069301  0.00888159  0.01498378\n",
            "  0.02637123 -0.01923097 -0.00717952 -0.04782164  0.03907159  0.02202847\n",
            " -0.05275417 -0.00614177  0.04844092 -0.03245337  0.01270713 -0.02165488\n",
            "  0.01873922  0.06639383  0.05582064 -0.08562532  0.00610438 -0.06674004\n",
            " -0.01766531  0.01620102 -0.06442948  0.03433492  0.04962416  0.01790563\n",
            "  0.03268484 -0.0138974  -0.01076586  0.01110834  0.07169168 -0.07435419\n",
            " -0.03884094 -0.08228942 -0.00322556  0.06943341  0.00421006 -0.08355347\n",
            " -0.02392834  0.00564408 -0.0099643   0.01234588  0.04618819 -0.03668099\n",
            "  0.06893206  0.02070074  0.04202449 -0.00982662  0.004982   -0.05994853\n",
            "  0.07139765  0.06013056 -0.00395361  0.07884447 -0.02161972 -0.0080986\n",
            " -0.04877734  0.06798881  0.03579017  0.03236601  0.01880645 -0.02589147\n",
            "  0.02714541 -0.00145066 -0.07591994  0.0195384  -0.03074082  0.01103066\n",
            " -0.00236972 -0.05084228 -0.02331687 -0.01886573  0.07775489  0.06085222\n",
            "  0.07696824 -0.00713248  0.02582064  0.00875587  0.00734652  0.01714352\n",
            "  0.02744237  0.06985958 -0.00434151  0.0150281   0.0056131  -0.00415525\n",
            " -0.03123924  0.02471363  0.08923053  0.03838678 -0.00377641 -0.02510157\n",
            " -0.05239334  0.05477389 -0.05668659  0.06966425  0.05166655 -0.02671028\n",
            " -0.00485085  0.06455849  0.07322502  0.05554793 -0.05164237 -0.03306397\n",
            "  0.07145651  0.03690751 -0.01157344 -0.03348219  0.04652622  0.02137782\n",
            "  0.02232642 -0.06051857 -0.03319316  0.0478918  -0.00821846 -0.06063398\n",
            "  0.08997937  0.0038742   0.07964138  0.0091426   0.0321263  -0.044991\n",
            " -0.07452471  0.03361058  0.04221833 -0.06838626 -0.02528254 -0.0733024\n",
            " -0.06427722  0.04100394 -0.01184626 -0.01212071  0.04274236 -0.07545153\n",
            " -0.026053    0.01647838  0.00137644 -0.09474962  0.03225951 -0.03223361\n",
            "  0.00226771 -0.03278165  0.01119078  0.09649383 -0.01072587 -0.02669916\n",
            "  0.00236464  0.00518142  0.02205302 -0.04222182  0.01750096 -0.05743179\n",
            " -0.04330861 -0.07834243  0.0275364   0.04007101  0.0395004   0.00836409\n",
            " -0.04945192  0.01165079  0.05326363  0.06523127  0.05430757  0.01284709\n",
            "  0.05596567  0.00954171 -0.05601789 -0.01490775  0.01581855 -0.04875726\n",
            "  0.0175812  -0.03655423 -0.04995537  0.03216295 -0.09101085  0.00611437\n",
            " -0.04397945 -0.06485641 -0.01765695  0.03543923  0.03359805  0.03548808\n",
            " -0.0276471  -0.02517797  0.05429016 -0.04452589  0.00873128 -0.04663507\n",
            "  0.02683338 -0.05035653 -0.02390623 -0.00183819  0.02263037 -0.04718935\n",
            "  0.04348256 -0.01023243 -0.03637148 -0.030401   -0.00064718  0.05961699\n",
            " -0.00304698  0.01476908 -0.00664017 -0.07461987  0.03803038 -0.03997244\n",
            " -0.07956375 -0.02505385 -0.08103379  0.07887599  0.04109212 -0.02528062\n",
            " -0.00305051 -0.05728317  0.0064679  -0.05769759 -0.00399961  0.05416717\n",
            " -0.00706781  0.00834124 -0.0021884   0.07605667  0.04247274 -0.02007022\n",
            " -0.04284704 -0.03518407 -0.09202836  0.00466267  0.07910336  0.05445262\n",
            "  0.02118769  0.01633579 -0.07348985  0.01603102  0.0409512   0.00499731\n",
            "  0.07423791  0.0223089  -0.08955832 -0.03043773 -0.00690283 -0.05573666\n",
            "  0.00977445  0.01096841 -0.078325   -0.00872904 -0.02148565  0.06101171\n",
            "  0.07887734  0.00346054 -0.01242634 -0.03129635  0.01465541 -0.02436907\n",
            "  0.06966115  0.08885241 -0.00302059  0.0129925   0.03011821  0.02425653\n",
            " -0.02050994 -0.01564532 -0.04626206  0.00322573  0.00328313  0.04140383\n",
            " -0.02030117  0.02448922 -0.06821147 -0.03280142  0.00017981 -0.02418604\n",
            " -0.02457525 -0.02952637 -0.04676633  0.0492935   0.00035072 -0.04274167\n",
            "  0.03810221 -0.01800198 -0.0030158   0.02995699  0.00570203  0.01764772\n",
            " -0.05774307  0.03316358  0.01309349  0.04735311 -0.01345565 -0.04039472\n",
            " -0.05449402  0.06135113  0.03385789 -0.03087298  0.06209387 -0.02981381\n",
            " -0.02658731 -0.02963331  0.04045937  0.00140912  0.0300354  -0.07099435\n",
            "  0.00661549 -0.06946058 -0.0684348   0.02927026  0.03013538  0.07370667\n",
            "  0.05863091  0.09086484 -0.06109345  0.05355793 -0.00892582  0.0118595\n",
            "  0.04618049  0.01902794 -0.04999999 -0.04556122 -0.00916397  0.02722127\n",
            "  0.03629794 -0.07514992  0.02847097  0.08381693 -0.06469326 -0.00381371\n",
            "  0.00038381 -0.00216872 -0.00123819  0.03273128  0.06587742 -0.01496852\n",
            "  0.04123859 -0.01387944 -0.08031549 -0.06564582  0.07423846 -0.06673401\n",
            "  0.05362619  0.0757209   0.07795952 -0.04981509 -0.01712305  0.08120856\n",
            " -0.02438353 -0.02605053 -0.00918132 -0.09171607 -0.05457199  0.00907802\n",
            "  0.03799893  0.06968086 -0.04683617 -0.00679065 -0.01141653 -0.03554538\n",
            " -0.00116133  0.0232379   0.03614055 -0.01136558 -0.02313601 -0.01004676\n",
            " -0.01769985 -0.00062453  0.01413062 -0.08318564  0.01604416 -0.08861189\n",
            " -0.0443763  -0.05104193  0.04298325  0.02574974  0.03124833 -0.01052034\n",
            "  0.06974696  0.02269101  0.05216752  0.01890912 -0.04793479 -0.01926927\n",
            "  0.02672003  0.05731779  0.0315438  -0.03553957  0.04482842  0.07791217\n",
            "  0.07458576  0.02051954 -0.00909592 -0.05198032  0.05175024 -0.08247866\n",
            " -0.02446434  0.05483037]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hYgqENKifFj"
      },
      "source": [
        "#3.SENTENCE -BERT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhqH0-M0i_u9",
        "outputId": "56bd4750-fe57-4211-f219-9c4600fc89ab"
      },
      "source": [
        "#importing sentencebert model\n",
        "bert = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")\n",
        "embeddings2=bert(sentences)\n",
        "print(embeddings2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.51884556  0.02918336  0.07145058 ...  0.22533715  0.01950222\n",
            "  -0.1289025 ]\n",
            " [ 0.5166956   0.00863559  0.13047293 ...  0.06873029  0.04432377\n",
            "   0.02298209]\n",
            " [ 0.6110389   0.1811815  -0.11061911 ... -0.09788384  0.09358283\n",
            "   0.07447077]\n",
            " ...\n",
            " [ 0.39123687 -0.01085754  0.07607286 ...  0.07567259 -0.1484504\n",
            "  -0.02365224]\n",
            " [ 0.24070688 -0.00535227  0.12521958 ... -0.1306146  -0.12194312\n",
            "   0.00996622]\n",
            " [ 0.3799187  -0.05745781  0.09742597 ...  0.0461409  -0.07855327\n",
            "   0.03973798]], shape=(8, 128), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvPoZ6R4jGzd",
        "outputId": "e4edd51f-a077-424e-8fdc-a83242173f58"
      },
      "source": [
        "print(\"shape=\",embeddings2[0].shape)\n",
        "#each sentence is converted into vector having 128 values\n",
        "print(\"The sentence: \",sentences[0],\"\\n is converted as : \\n{}\".format(embeddings2[0]))\n",
        "shape= (128,)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape= (128,)\n",
            "The sentence:  A paragraph is a series of sentences that are organized and coherent, and are \n",
            "all  related  to  a  single  topic. \n",
            " is converted as : \n",
            "[ 0.51884556  0.02918336  0.07145058  0.04535037 -0.04259718 -0.1654925\n",
            " -0.103632   -0.0106116  -0.19418633  0.18560012  0.05228718 -0.1996645\n",
            " -0.08536236  0.03365118 -0.14633818 -0.02451333 -0.07473224  0.0438432\n",
            " -0.18141116  0.1372393   0.0136739   0.07080507 -0.00786687 -0.08535285\n",
            "  0.0715998  -0.06499769 -0.08562539 -0.02720456 -0.05636027 -0.00261944\n",
            " -0.01944907 -0.04633158 -0.07786479 -0.16420066 -0.03604371 -0.09477271\n",
            "  0.05015939 -0.10466915 -0.07002265  0.0187032   0.09759199 -0.08157597\n",
            "  0.20161884  0.01257148 -0.06885625  0.21009818 -0.01509479 -0.13517898\n",
            " -0.09388355  0.01013749 -0.02629396 -0.06578662  0.04543499  0.04652723\n",
            "  0.10455509  0.05183478  0.10705721 -0.10057095  0.07927544 -0.14144531\n",
            " -0.10567372 -0.08833035 -0.07270256 -0.05692196  0.0400563  -0.19360085\n",
            " -0.14046225 -0.01617921  0.13456236 -0.03750716  0.1783527  -0.05664362\n",
            " -0.05489332 -0.03530612 -0.08779504 -0.05620974 -0.15214193 -0.13144818\n",
            " -0.11252512 -0.12801613 -0.00715148 -0.07923457  0.00090769  0.08723561\n",
            " -0.03939961 -0.0216552  -0.01878057  0.13647555  0.3296772   0.2150382\n",
            " -0.05852424  0.01502363 -0.06728545 -0.01190338 -0.00726737  0.08105026\n",
            "  0.1057744  -0.11777685 -0.18084489  0.12395908 -0.01560009  0.12574704\n",
            "  0.07041188  0.19995967  0.13861457 -0.03607485  0.11367121 -0.07071587\n",
            " -0.07011928  0.0738837  -0.17090002 -0.02478953 -0.07337482 -0.06516083\n",
            "  0.19690074 -0.16751876 -0.06475157 -0.07023422 -0.01588102 -0.00151716\n",
            "  0.08563422  0.00355345 -0.00587897 -0.1961055   0.00305911  0.22533715\n",
            "  0.01950222 -0.1289025 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6BxkE2vjN9J"
      },
      "source": [
        "#4.Implementing ELMOS\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgR8lLzSjZkB"
      },
      "source": [
        "!pip install \"tensorflow>=2.0.0\"\n",
        "!pip install --upgrade tensorflow-hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpFoTt24jqkd",
        "outputId": "cd5a4230-0655-4922-f362-97e9d563f6e0"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()\n",
        "#1024 sized vectors\n",
        "elmo=hub.Module(\"https://tfhub.dev/google/elmo/3\",trainable=True)\n",
        "embeddings=elmo(\n",
        "    sentences,\n",
        "    signature=\"default\",\n",
        "    as_dict=True)[\"elmo\"]\n",
        "init=tf.initialize_all_variables()\n",
        "sess=tf.Session()\n",
        "sess.run(init)\n",
        "print(\"\\n\\n\")\n",
        "print(sess.run(embeddings[0]))\n",
        "print(\"shape=\",embeddings[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py:247: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py:247: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "[[ 0.29286996 -0.14378002 -0.32574052 ... -0.42214906 -0.26807797\n",
            "  -0.06121337]\n",
            " [-0.59441644  0.09640661  0.50537676 ...  0.2956011   0.36285305\n",
            "   0.46462518]\n",
            " [-0.17083307 -0.18744141 -0.27626717 ... -0.6752867   0.36227596\n",
            "   0.7219782 ]\n",
            " ...\n",
            " [-0.02840841 -0.04353216  0.04130163 ...  0.02583168 -0.01429836\n",
            "  -0.01650422]\n",
            " [-0.02840841 -0.04353216  0.04130163 ...  0.02583168 -0.01429836\n",
            "  -0.01650422]\n",
            " [-0.02840841 -0.04353216  0.04130163 ...  0.02583168 -0.01429836\n",
            "  -0.01650422]]\n",
            "shape= (32, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjNITNI0jmEs"
      },
      "source": [
        "#5.GP2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXSDldY_j1Vb",
        "outputId": "cc4ca329-586d-447d-ef7f-ddd3224f6beb"
      },
      "source": [
        "import torch\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN5Sse19kUuC"
      },
      "source": [
        "import transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Kk7ysFekLhu"
      },
      "source": [
        "gptokenizer=transformers.GPT2Tokenizer.from_pretrained('gpt2-large')\n",
        "model=transformers.GPT2LMHeadModel.from_pretrained('gpt2-large')\n",
        "output=gptokenizer.encode(my_string,add_special_tokens=False,return_tensors=\"pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEeq2kWMkYQL",
        "outputId": "e56d5c76-060f-4908-c3af-cac856c4edc3"
      },
      "source": [
        "print(\"shape=\",output.shape)\n",
        "output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape= torch.Size([1, 264])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   32,  7322,   318,   257,  2168,   286, 13439,   326,   389,  8389,\n",
              "           290, 24870,    11,   290,   389,   220,   198,   439,   220,  3519,\n",
              "           220,   284,   220,   257,   220,  2060,   220,  7243,    13,   220,\n",
              "         16699,   220,   790,   220,  3704,   220,   286,   220,  3597,   220,\n",
              "           345,   220,   466,   220,   326,   220,   318,   220,   198,  6511,\n",
              "           263,   220,   621,   220,   257,   220,  1178,   220, 13439,   220,\n",
              "           815,   220,   307,   220,  8389,   220,   656,   220, 23549,    13,\n",
              "           220,   770,   220,   318,   220,   198, 13893, 23549,   905,   257,\n",
              "          9173,   810,   262, 45944,  3279,   286,   281, 14268,  2221,   220,\n",
              "           198,   392,   886,    11,   290,  4145,  1037,   262,  9173,   766,\n",
              "           262,  4009,   286,   262, 14268,   290, 13180,   220,   198,   896,\n",
              "          1388,  2173,    13,   198, 10044,  6111,    82,   220,   460,   220,\n",
              "          3994,   220,   867,   220,  1180,   220,  6982,   220,   286,   220,\n",
              "          1321,    13,   220,   317,   220,  7322,   220,   198, 24089,   220,\n",
              "          3994,   220,   257,   220,  2168,   220,   286,   220,  4506,   220,\n",
              "          6096,   220,   393,   220,   257,   220,  2060,   220,   890,   220,\n",
              "         20936,   220,   286,   220,   257,   220,   198, 24622,   220,   966,\n",
              "            13,   220,   632,   220,  1244,   220,  6901,   220,   257,   220,\n",
              "          1295,    11,   220,  2095,    11,   220,   393,   220,  1429,    26,\n",
              "           220,  6664,   378,   220,   257,   220,   198, 25076,   286,  2995,\n",
              "            26,  8996,   393,  6273,   734,   393,   517,  1243,    26, 36509,\n",
              "          3709,   656,   220,   198,    66, 26129,    26,   220,   393,   220,\n",
              "          6901,   220,  5640,   220,   290,   220,  3048,    13,   220, 22250,\n",
              "           220,   286,   220,   262,   220,  1611,   220,   286,   220,   198,\n",
              "         17018,   484,  3994,    11,   477, 23549,  2648,  1728,  9695,    13,\n",
              "          1881,   220,   198,  1659,   262,   749,  1593,   286,   777,   318,\n",
              "           257,  7243,  6827,    13]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYiIlKEWkgOH"
      },
      "source": [
        "# 2. Find named entities (NER) for the above paragraph?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTn6C0eQkhDt",
        "outputId": "e0a47c22-7f28-40fa-cf64-581a03c18199"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "ner=spacy.load('en')\n",
        "result=ner(my_string)\n",
        "\n",
        "for word in result.ents:\n",
        "  print(word.text,word.label_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "two CARDINAL\n",
            "One CARDINAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NJd9IsizkjrI",
        "outputId": "69a78b26-5f6a-4d6b-a2d0-f8ffa7baac88"
      },
      "source": [
        "spacy.explain('GPE')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Countries, cities, states'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "12GsuNrgkoKz",
        "outputId": "56a26ed8-bd3b-4c49-cea7-6c7ad36c7b73"
      },
      "source": [
        "#better visualisation of entity recognition\n",
        "displacy.render(result,style=\"ent\",jupyter=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A paragraph is a series of sentences that are organized and coherent, and are </br>all  related  to  a  single  topic.  Almost  every  piece  of  writing  you  do  that  is </br>longer  than  a  few  sentences  should  be  organized  into  paragraphs.  This  is </br>because paragraphs show a reader where the subdivisions of an essay begin </br>and end, and thus help the reader see the organization of the essay and grasp </br>its main points.</br>Paragraphs  can  contain  many  different  kinds  of  information.  A  paragraph </br>could  contain  a  series  of  brief  examples  or  a  single  long  illustration  of  a </br>general  point.  It  might  describe  a  place,  character,  or  process;  narrate  a </br>series of events; compare or contrast \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    two\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " or more things; classify items into </br>categories;  or  describe  causes  and  effects.  Regardless  of  the  kind  of </br>information they contain, all paragraphs share certain characteristics. \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    One\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " \n",
              "of the most important of these is a topic sentence.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3xqE9xrkoVH",
        "outputId": "0f41fcca-668e-4f60-a578-695e196c0d47"
      },
      "source": [
        "# finding named entities of another paragraph\n",
        "resultss=ner(\"Cricket was introduced to India by British sailors in the 18th century, and the first cricket club was established in 1792. India's national cricket team did not play its first Test match until 25 June 1932 at Lord's, becoming the sixth team to be granted test cricket status. From 1932 India had to wait until 1952, almost 20 years for its first Test victory. In its first fifty years of international cricket, India didn't gain much success, winning only 35 of the first 196 Test matches it played. The team, however, gained strength in the 1970s with the emergence of players like Gavaskar, Viswanath, Kapil Dev, and the Indian spin quartet.\")\n",
        "for word in resultss.ents:\n",
        "  print(word.text,word.label_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "India GPE\n",
            "British NORP\n",
            "the 18th century DATE\n",
            "first ORDINAL\n",
            "1792 DATE\n",
            "India GPE\n",
            "first ORDINAL\n",
            "25 June 1932 DATE\n",
            "sixth ORDINAL\n",
            "1932 DATE\n",
            "India GPE\n",
            "1952 DATE\n",
            "almost 20 years DATE\n",
            "first ORDINAL\n",
            "its first fifty years DATE\n",
            "India GPE\n",
            "only 35 CARDINAL\n",
            "first ORDINAL\n",
            "196 CARDINAL\n",
            "the 1970s DATE\n",
            "Gavaskar PERSON\n",
            "Viswanath ORG\n",
            "Kapil Dev PERSON\n",
            "Indian NORP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "-p3QwPeDksev",
        "outputId": "14b1b12b-4d3f-423f-ecbc-ce56edfc278e"
      },
      "source": [
        "#better visualisation of entity recognition\n",
        "displacy.render(resultss,style=\"ent\",jupyter=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Cricket was introduced to \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    India\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " by \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    British\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " sailors in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the 18th century\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", and the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    first\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " cricket club was established in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1792\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    India\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "'s national cricket team did not play its \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    first\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " Test match until \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    25 June 1932\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " at Lord's, becoming the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    sixth\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " team to be granted test cricket status. From \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1932\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    India\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " had to wait until \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1952\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    almost 20 years\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " for its \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    first\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " Test victory. In \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    its first fifty years\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " of international cricket, \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    India\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " didn't gain much success, winning \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    only 35\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " of the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    first\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    196\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " Test matches it played. The team, however, gained strength in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the 1970s\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " with the emergence of players like \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Gavaskar\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Viswanath\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Kapil Dev\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", and the \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Indian\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " spin quartet.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVDBvE9jkwot"
      },
      "source": [
        "#3. Find similar sentences(repeated sentences) from the above paragraph?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku1nrcrxkzrq"
      },
      "source": [
        "pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uihJEFdMkz0L"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOj6G2I5k5on",
        "outputId": "30646ebd-4e95-40de-d8e4-099c27cd7345"
      },
      "source": [
        "se_embeddings = sbert_model.encode(sentences)\n",
        "q1_vec= sbert_model.encode(sentences[0])\n",
        "\n",
        "#cosine similarity function\n",
        "#identifies similarity between 2 sentences\n",
        "def cosine(u, v):\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
        "\n",
        "for sent in sentences:\n",
        "  sim = cosine(q1_vec, sbert_model.encode([sent])[0])\n",
        "  #if similarity ==1 => repeated sentence\n",
        "  #if similarity > 0.6 => similar sentence\n",
        "  if sim>0.6:\n",
        "    print(\"Sentence1 =\",sentences[0],\"\\n \\nSentence2=\", sent, \"\\n\\nsimilarity = \", sim,end=\"\\n ----------------------------- \\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are \n",
            "all  related  to  a  single  topic. \n",
            " \n",
            "Sentence2= A paragraph is a series of sentences that are organized and coherent, and are \n",
            "all  related  to  a  single  topic. \n",
            "\n",
            "similarity =  1.0\n",
            " ----------------------------- \n",
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are \n",
            "all  related  to  a  single  topic. \n",
            " \n",
            "Sentence2= Almost  every  piece  of  writing  you  do  that  is \n",
            "longer  than  a  few  sentences  should  be  organized  into  paragraphs. \n",
            "\n",
            "similarity =  0.64775366\n",
            " ----------------------------- \n",
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are \n",
            "all  related  to  a  single  topic. \n",
            " \n",
            "Sentence2= A  paragraph \n",
            "could  contain  a  series  of  brief  examples  or  a  single  long  illustration  of  a \n",
            "general  point. \n",
            "\n",
            "similarity =  0.6927288\n",
            " ----------------------------- \n",
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are \n",
            "all  related  to  a  single  topic. \n",
            " \n",
            "Sentence2= Regardless  of  the  kind  of \n",
            "information they contain, all paragraphs share certain characteristics. \n",
            "\n",
            "similarity =  0.787384\n",
            " ----------------------------- \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kfLJrTSk9HD"
      },
      "source": [
        "#4. Explain POS tagging with HMM?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ-uf_Jnp_f5"
      },
      "source": [
        "\n",
        "Parts of Speech Tagging (POS): It is a process of converting a sentence to forms  list of words, list of tuples (where each tuple is having a form (word, tag)). The tag in case of is a part-of-speech tag, and signifies whether the word is a noun, adjective, verb, and so on. reading a sentence and being able to identify what words act as nouns, pronouns, verbs, adverbs, and so on. All these are referred to as the part of speech tags.\n",
        " According to Wikipedia, part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging or word-category disambiguation, is the process of marking up a word in a text as corresponding to a particular part of speech, based on both its definition and its context i.e. its relationship with adjacent and related words in a phrase, sentence, or paragraph.\n",
        "\n",
        "\n",
        "\n",
        "Default tagging is a basic step for the part-of-speech tagging. It is performed using the DefaultTagger class. The DefaultTagger class takes tag as a single argument. NN is the tag for a singular noun. DefaultTagger is most useful when it gets to work with most common part-of-speech tag. thats why a noun tag is recommended.\n",
        "\n",
        "POS tagging with Hidden Markov Model\n",
        "HMM (Hidden Markov Model) is a Stochastic technique for POS tagging. Hidden Markov models are known for their applications to reinforcement learning and temporal pattern recognition such as speech, handwriting, gesture recognition, musical score following, partial discharges, and bioinformatics.\n",
        "\n",
        "Let us consider an example proposed by Dr.Luis Serrano and find out how HMM selects an appropriate tag sequence for a sentence.\n",
        "\n",
        "\n",
        "In this example, we consider only 3 POS tags that are noun, model and verb. Let the sentence  Ted will spot Will  be tagged as noun, model, verb and a noun and to calculate the probability associated with this particular sequence of tags we require their Transition probability and Emission probability.\n",
        "\n",
        "The transition probability is the likelihood of a particular sequence for example, how likely is that a noun is followed by a model and a model by a verb and a verb by a noun. This probability is known as Transition probability. It should be high for a particular sequence to be correct.\n",
        "\n",
        "Now, what is the probability that the word Ted is a noun, will is a model, spot is a verb and Will is a noun. These sets of probabilities are Emission probabilities and should be high for our tagging to be likely.\n",
        "\n",
        "Let us calculate the above two probabilities for the set of sentences below\n",
        "\n",
        "Mary Jane can see Will\n",
        "Spot will see Mary\n",
        "Will Jane spot Mary?\n",
        "Mary will pat Spot\n",
        "Note that Mary Jane, Spot, and Will are all names.\n",
        "\n",
        "\n",
        "In the above sentences, the word Mary appears four times as a noun. and see appears two times as a verb. we need to calculate the probabilitiy of a word appearing as noun, verb or model. to do this, we need to calculate the emission probabilities, which represented using below table.\n",
        "\n",
        "\n",
        "Now divide each column by the total number of their appearances .for example, noun appears nine times in the above sentences, so divide each term by 9 in the noun column. and repeat the same for all remaining processes. We get the following table after this operation.\n",
        "\n",
        "\n",
        "From the above table, we can conclude that\n",
        "\n",
        "The probability that Mary is Noun = 4/9\n",
        "\n",
        "The probability that Mary is Model = 0\n",
        "\n",
        "The probability that Mary is Verb = 0\n",
        "\n",
        "The probability that Will is Noun = 1/9\n",
        "\n",
        "The probability that Will is Model = 3/4\n",
        "\n",
        "In a similar manner, we can analyze rest of the probabilities. These are the emission probabilities.\n",
        "\n",
        "Next, we have to calculate the transition probabilities, so define two more tags < S > and < E >. < S > is placed at the beginning of each sentence and < E > at the end as shown in the figure below.\n",
        "\n",
        "since for first and last word there is no previous and next words, so we are adding extra dummy words. i.e < E > and < S >\n",
        "\n",
        "\n",
        "now we need to create a table and fill it with the co-occurrence counts of the tags.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}